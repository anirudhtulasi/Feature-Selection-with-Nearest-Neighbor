Welcome to Bertie Woosters Feature Selection Algorithm.
Please select one : 1 - Synthetic Dataset, 2 - Real-World Dataset
2
Please select one : 1 - Red wine dataset, 2 - White wine dataset
1
This dataset has 11 features (not including the class attribute), with 1599 instances.
Please select the search algorithm: 1 - Forward Selection, 2 - Backward Elimination, 3 - Optimized Forward Selection, 4 - Optimized Backward Elimination
3
Starting Optimized Forward Selection...
Running nearest neighbor with all 11 features, using "leaving-one-out" evaluation, I get accuracy of 42.6%

Using feature(s) [1] accuracy is 41.2%
Using feature(s) [2] accuracy is 41.2%
Using feature(s) [3] accuracy is 38.2%
Using feature(s) [4] accuracy is 35.6%
Using feature(s) [5] accuracy is 39.2%
Using feature(s) [6] accuracy is 37.0%
Using feature(s) [7] accuracy is 41.0%
Using feature(s) [8] accuracy is 45.0%
Using feature(s) [9] accuracy is 37.2%
Using feature(s) [10] accuracy is 35.4%
Using feature(s) [11] accuracy is 41.8%
Progress: 1/11 features selected.

Feature set [8] was best, accuracy is 45.0%
Using feature(s) [8, 1] accuracy is 56.6%
Using feature(s) [8, 2] accuracy is 58.1%
Using feature(s) [8, 3] accuracy is 56.4%
Using feature(s) [8, 4] accuracy is 53.6%
Using feature(s) [8, 5] accuracy is 57.4%
Using feature(s) [8, 6] accuracy is 56.8%
Using feature(s) [8, 7] accuracy is 57.7%
Using feature(s) [8, 9] accuracy is 55.7%
Using feature(s) [8, 10] accuracy is 58.5%
Using feature(s) [8, 11] accuracy is 61.2%
Progress: 2/11 features selected.

Feature set [8, 11] was best, accuracy is 61.2%
Using feature(s) [8, 11, 1] accuracy is 64.1%
Using feature(s) [8, 11, 2] accuracy is 64.6%
Using feature(s) [8, 11, 3] accuracy is 63.8%
Using feature(s) [8, 11, 4] accuracy is 62.3%
Using feature(s) [8, 11, 5] accuracy is 63.9%
Using feature(s) [8, 11, 6] accuracy is 63.8%
Using feature(s) [8, 11, 7] accuracy is 64.7%
Using feature(s) [8, 11, 9] accuracy is 62.8%
Using feature(s) [8, 11, 10] accuracy is 61.0%
Progress: 3/11 features selected.

Feature set [8, 11, 7] was best, accuracy is 64.7%
Using feature(s) [8, 11, 7, 1] accuracy is 63.9%
Using feature(s) [8, 11, 7, 2] accuracy is 66.0%
Using feature(s) [8, 11, 7, 3] accuracy is 65.0%
Using feature(s) [8, 11, 7, 4] accuracy is 64.8%
Using feature(s) [8, 11, 7, 5] accuracy is 64.5%
Using feature(s) [8, 11, 7, 6] accuracy is 63.9%
Using feature(s) [8, 11, 7, 9] accuracy is 63.9%
Using feature(s) [8, 11, 7, 10] accuracy is 64.0%
Progress: 4/11 features selected.

Feature set [8, 11, 7, 2] was best, accuracy is 66.0%
Using feature(s) [8, 11, 7, 2, 1] accuracy is 65.2%
Using feature(s) [8, 11, 7, 2, 3] accuracy is 65.5%
Using feature(s) [8, 11, 7, 2, 4] accuracy is 66.0%
Using feature(s) [8, 11, 7, 2, 5] accuracy is 65.2%
Using feature(s) [8, 11, 7, 2, 6] accuracy is 65.6%
Using feature(s) [8, 11, 7, 2, 9] accuracy is 64.4%
Using feature(s) [8, 11, 7, 2, 10] accuracy is 66.1%
Progress: 5/11 features selected.

Feature set [8, 11, 7, 2, 10] was best, accuracy is 66.1%
Using feature(s) [8, 11, 7, 2, 10, 1] accuracy is 63.8%
Using feature(s) [8, 11, 7, 2, 10, 3] accuracy is 67.2%
Using feature(s) [8, 11, 7, 2, 10, 4] accuracy is 66.5%
Using feature(s) [8, 11, 7, 2, 10, 5] accuracy is 66.2%
Using feature(s) [8, 11, 7, 2, 10, 6] accuracy is 66.5%
Using feature(s) [8, 11, 7, 2, 10, 9] accuracy is 64.9%
Progress: 6/11 features selected.

Feature set [8, 11, 7, 2, 10, 3] was best, accuracy is 67.2%
Using feature(s) [8, 11, 7, 2, 10, 3, 1] accuracy is 65.6%
Using feature(s) [8, 11, 7, 2, 10, 3, 4] accuracy is 66.9%
Using feature(s) [8, 11, 7, 2, 10, 3, 5] accuracy is 67.5%
Using feature(s) [8, 11, 7, 2, 10, 3, 6] accuracy is 65.6%
Using feature(s) [8, 11, 7, 2, 10, 3, 9] accuracy is 65.0%
Progress: 7/11 features selected.

Feature set [8, 11, 7, 2, 10, 3, 5] was best, accuracy is 67.5%
Using feature(s) [8, 11, 7, 2, 10, 3, 5, 1] accuracy is 66.4%
Using feature(s) [8, 11, 7, 2, 10, 3, 5, 4] accuracy is 66.9%
Using feature(s) [8, 11, 7, 2, 10, 3, 5, 6] accuracy is 65.2%
Using feature(s) [8, 11, 7, 2, 10, 3, 5, 9] accuracy is 65.0%
Progress: 8/11 features selected.

Using feature(s) [8, 11, 7, 2, 10, 3, 5, 4, 1] accuracy is 67.0%
Using feature(s) [8, 11, 7, 2, 10, 3, 5, 4, 6] accuracy is 66.2%
Using feature(s) [8, 11, 7, 2, 10, 3, 5, 4, 9] accuracy is 66.2%
Progress: 9/11 features selected.

Using feature(s) [8, 11, 7, 2, 10, 3, 5, 4, 1, 6] accuracy is 67.0%
Using feature(s) [8, 11, 7, 2, 10, 3, 5, 4, 1, 9] accuracy is 66.2%
Progress: 10/11 features selected.

Using feature(s) [8, 11, 7, 2, 10, 3, 5, 4, 1, 6, 9] accuracy is 65.9%
Progress: 11/11 features selected.

The best feature subset is [8, 11, 7, 2, 10, 3, 5], which has an accuracy of 67.5%
The best three-feature subset is [8, 11, 7], which has an accuracy of 64.7%

Elapsed time: 0.424 seconds
(base) prakashkolluru@Prakashs-MBP AI Final script 2 % python3 main.py
Welcome to Bertie Woosters Feature Selection Algorithm.
Please select one : 1 - Synthetic Dataset, 2 - Real-World Dataset
2
Please select one : 1 - Red wine dataset, 2 - White wine dataset
1
This dataset has 11 features (not including the class attribute), with 1599 instances.
Please select the search algorithm: 1 - Forward Selection, 2 - Backward Elimination, 3 - Optimized Forward Selection, 4 - Optimized Backward Elimination
4
Starting Optimized Backward Elimination...
Running nearest neighbor with all 11 features, using "leaving-one-out" evaluation, I get accuracy of 65.9%

Using feature(s) [2, 3, 4, 5, 6, 7, 8, 9, 10, 11] accuracy is 65.5%
Using feature(s) [1, 3, 4, 5, 6, 7, 8, 9, 10, 11] accuracy is 66.7%
Using feature(s) [1, 2, 4, 5, 6, 7, 8, 9, 10, 11] accuracy is 65.0%
Using feature(s) [1, 2, 3, 5, 6, 7, 8, 9, 10, 11] accuracy is 65.3%
Using feature(s) [1, 2, 3, 4, 6, 7, 8, 9, 10, 11] accuracy is 65.6%
Using feature(s) [1, 2, 3, 4, 5, 7, 8, 9, 10, 11] accuracy is 66.2%
Using feature(s) [1, 2, 3, 4, 5, 6, 8, 9, 10, 11] accuracy is 65.1%
Using feature(s) [1, 2, 3, 4, 5, 6, 7, 9, 10, 11] accuracy is 65.9%
Using feature(s) [1, 2, 3, 4, 5, 6, 7, 8, 10, 11] accuracy is 67.0%
Using feature(s) [1, 2, 3, 4, 5, 6, 7, 8, 9, 11] accuracy is 66.4%
Using feature(s) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] accuracy is 65.2%
Progress: feature size is : 10

Feature set [1, 2, 3, 4, 5, 6, 7, 8, 10, 11] was best, accuracy is 67.0%
Using feature(s) [2, 3, 4, 5, 6, 7, 8, 10, 11] accuracy is 66.2%
Using feature(s) [1, 3, 4, 5, 6, 7, 8, 10, 11] accuracy is 67.2%
Using feature(s) [1, 2, 4, 5, 6, 7, 8, 10, 11] accuracy is 66.3%
Using feature(s) [1, 2, 3, 5, 6, 7, 8, 10, 11] accuracy is 66.7%
Using feature(s) [1, 2, 3, 4, 6, 7, 8, 10, 11] accuracy is 67.0%
Using feature(s) [1, 2, 3, 4, 5, 7, 8, 10, 11] accuracy is 67.0%
Using feature(s) [1, 2, 3, 4, 5, 6, 8, 10, 11] accuracy is 66.1%
Using feature(s) [1, 2, 3, 4, 5, 6, 7, 10, 11] accuracy is 66.5%
Using feature(s) [1, 2, 3, 4, 5, 6, 7, 8, 11] accuracy is 66.5%
Using feature(s) [1, 2, 3, 4, 5, 6, 7, 8, 10] accuracy is 65.5%
Progress: feature size is : 9

Feature set [1, 3, 4, 5, 6, 7, 8, 10, 11] was best, accuracy is 67.2%
Using feature(s) [3, 4, 5, 6, 7, 8, 10, 11] accuracy is 65.9%
Using feature(s) [1, 4, 5, 6, 7, 8, 10, 11] accuracy is 66.0%
Using feature(s) [1, 3, 5, 6, 7, 8, 10, 11] accuracy is 66.2%
Using feature(s) [1, 3, 4, 6, 7, 8, 10, 11] accuracy is 66.4%
Using feature(s) [1, 3, 4, 5, 7, 8, 10, 11] accuracy is 66.5%
Using feature(s) [1, 3, 4, 5, 6, 8, 10, 11] accuracy is 67.0%
Using feature(s) [1, 3, 4, 5, 6, 7, 10, 11] accuracy is 66.7%
Using feature(s) [1, 3, 4, 5, 6, 7, 8, 11] accuracy is 67.3%
Using feature(s) [1, 3, 4, 5, 6, 7, 8, 10] accuracy is 65.2%
Progress: feature size is : 8

Feature set [1, 3, 4, 5, 6, 7, 8, 11] was best, accuracy is 67.3%
Using feature(s) [3, 4, 5, 6, 7, 8, 11] accuracy is 65.4%
Using feature(s) [1, 4, 5, 6, 7, 8, 11] accuracy is 65.9%
Using feature(s) [1, 3, 5, 6, 7, 8, 11] accuracy is 66.2%
Using feature(s) [1, 3, 4, 6, 7, 8, 11] accuracy is 67.0%
Using feature(s) [1, 3, 4, 5, 7, 8, 11] accuracy is 66.5%
Using feature(s) [1, 3, 4, 5, 6, 8, 11] accuracy is 66.3%
Using feature(s) [1, 3, 4, 5, 6, 7, 11] accuracy is 66.1%
Using feature(s) [1, 3, 4, 5, 6, 7, 8] accuracy is 64.0%
Progress: feature size is : 7

Using feature(s) [3, 4, 6, 7, 8, 11] accuracy is 65.5%
Using feature(s) [1, 4, 6, 7, 8, 11] accuracy is 66.1%
Using feature(s) [1, 3, 6, 7, 8, 11] accuracy is 66.2%
Using feature(s) [1, 3, 4, 7, 8, 11] accuracy is 65.9%
Using feature(s) [1, 3, 4, 6, 8, 11] accuracy is 66.2%
Using feature(s) [1, 3, 4, 6, 7, 11] accuracy is 66.9%
Using feature(s) [1, 3, 4, 6, 7, 8] accuracy is 63.2%
Progress: feature size is : 6

Using feature(s) [3, 4, 6, 7, 11] accuracy is 66.2%
Using feature(s) [1, 4, 6, 7, 11] accuracy is 65.5%
Using feature(s) [1, 3, 6, 7, 11] accuracy is 66.0%
Using feature(s) [1, 3, 4, 7, 11] accuracy is 65.9%
Using feature(s) [1, 3, 4, 6, 11] accuracy is 66.4%
Using feature(s) [1, 3, 4, 6, 7] accuracy is 63.1%
Progress: feature size is : 5

Using feature(s) [3, 4, 6, 11] accuracy is 64.7%
Using feature(s) [1, 4, 6, 11] accuracy is 64.8%
Using feature(s) [1, 3, 6, 11] accuracy is 65.6%
Using feature(s) [1, 3, 4, 11] accuracy is 65.2%
Using feature(s) [1, 3, 4, 6] accuracy is 60.5%
Progress: feature size is : 4

Using feature(s) [3, 6, 11] accuracy is 64.9%
Using feature(s) [1, 6, 11] accuracy is 63.9%
Using feature(s) [1, 3, 11] accuracy is 62.8%
Using feature(s) [1, 3, 6] accuracy is 59.3%
Progress: feature size is : 3

Using feature(s) [6, 11] accuracy is 53.6%
Using feature(s) [3, 11] accuracy is 58.3%
Using feature(s) [3, 6] accuracy is 52.7%
Progress: feature size is : 2

Using feature(s) [11] accuracy is 39.5%
Using feature(s) [3] accuracy is 33.1%
Progress: feature size is : 1

The best feature subset is [1, 3, 4, 5, 6, 7, 8, 11], which has an accuracy of 67.3%

Elapsed time: 0.497 seconds
(base) prakashkolluru@Prakashs-MBP AI Final script 2 % python3 main.py
Welcome to Bertie Woosters Feature Selection Algorithm.
Please select one : 1 - Synthetic Dataset, 2 - Real-World Dataset
2
Please select one : 1 - Red wine dataset, 2 - White wine dataset
2
This dataset has 11 features (not including the class attribute), with 4898 instances.
Please select the search algorithm: 1 - Forward Selection, 2 - Backward Elimination, 3 - Optimized Forward Selection, 4 - Optimized Backward Elimination
3
Starting Optimized Forward Selection...
Running nearest neighbor with all 11 features, using "leaving-one-out" evaluation, I get accuracy of 44.9%

Using feature(s) [1] accuracy is 31.6%
Using feature(s) [2] accuracy is 37.7%
Using feature(s) [3] accuracy is 34.4%
Using feature(s) [4] accuracy is 38.1%
Using feature(s) [5] accuracy is 37.3%
Using feature(s) [6] accuracy is 38.1%
Using feature(s) [7] accuracy is 36.2%
Using feature(s) [8] accuracy is 42.0%
Using feature(s) [9] accuracy is 34.5%
Using feature(s) [10] accuracy is 30.9%
Using feature(s) [11] accuracy is 39.9%
Progress: 1/11 features selected.

Feature set [8] was best, accuracy is 42.0%
Using feature(s) [8, 1] accuracy is 57.0%
Using feature(s) [8, 2] accuracy is 56.6%
Using feature(s) [8, 3] accuracy is 56.5%
Using feature(s) [8, 4] accuracy is 58.9%
Using feature(s) [8, 5] accuracy is 57.6%
Using feature(s) [8, 6] accuracy is 57.9%
Using feature(s) [8, 7] accuracy is 58.7%
Using feature(s) [8, 9] accuracy is 57.5%
Using feature(s) [8, 10] accuracy is 56.2%
Using feature(s) [8, 11] accuracy is 57.9%
Progress: 2/11 features selected.

Feature set [8, 4] was best, accuracy is 58.9%
Using feature(s) [8, 4, 1] accuracy is 62.6%
Using feature(s) [8, 4, 2] accuracy is 62.1%
Using feature(s) [8, 4, 3] accuracy is 61.6%
Using feature(s) [8, 4, 5] accuracy is 61.6%
Using feature(s) [8, 4, 6] accuracy is 61.5%
Using feature(s) [8, 4, 7] accuracy is 62.2%
Using feature(s) [8, 4, 9] accuracy is 62.4%
Using feature(s) [8, 4, 10] accuracy is 61.2%
Using feature(s) [8, 4, 11] accuracy is 63.1%
Progress: 3/11 features selected.

Feature set [8, 4, 11] was best, accuracy is 63.1%
Using feature(s) [8, 4, 11, 1] accuracy is 64.4%
Using feature(s) [8, 4, 11, 2] accuracy is 63.0%
Using feature(s) [8, 4, 11, 3] accuracy is 63.3%
Using feature(s) [8, 4, 11, 5] accuracy is 63.7%
Using feature(s) [8, 4, 11, 6] accuracy is 63.6%
Using feature(s) [8, 4, 11, 7] accuracy is 63.0%
Using feature(s) [8, 4, 11, 9] accuracy is 62.9%
Using feature(s) [8, 4, 11, 10] accuracy is 62.9%
Progress: 4/11 features selected.

Feature set [8, 4, 11, 1] was best, accuracy is 64.4%
Using feature(s) [8, 4, 11, 1, 2] accuracy is 64.1%
Using feature(s) [8, 4, 11, 1, 3] accuracy is 65.1%
Using feature(s) [8, 4, 11, 1, 5] accuracy is 64.8%
Using feature(s) [8, 4, 11, 1, 6] accuracy is 64.7%
Using feature(s) [8, 4, 11, 1, 7] accuracy is 63.8%
Using feature(s) [8, 4, 11, 1, 9] accuracy is 64.0%
Using feature(s) [8, 4, 11, 1, 10] accuracy is 63.4%
Progress: 5/11 features selected.

Feature set [8, 4, 11, 1, 3] was best, accuracy is 65.1%
Using feature(s) [8, 4, 11, 1, 3, 2] accuracy is 65.7%
Using feature(s) [8, 4, 11, 1, 3, 5] accuracy is 65.3%
Using feature(s) [8, 4, 11, 1, 3, 6] accuracy is 64.9%
Using feature(s) [8, 4, 11, 1, 3, 7] accuracy is 64.2%
Using feature(s) [8, 4, 11, 1, 3, 9] accuracy is 64.8%
Using feature(s) [8, 4, 11, 1, 3, 10] accuracy is 64.5%
Progress: 6/11 features selected.

Feature set [8, 4, 11, 1, 3, 2] was best, accuracy is 65.7%
Using feature(s) [8, 4, 11, 1, 3, 2, 5] accuracy is 65.3%
Using feature(s) [8, 4, 11, 1, 3, 2, 6] accuracy is 65.7%
Using feature(s) [8, 4, 11, 1, 3, 2, 7] accuracy is 65.5%
Using feature(s) [8, 4, 11, 1, 3, 2, 9] accuracy is 65.9%
Using feature(s) [8, 4, 11, 1, 3, 2, 10] accuracy is 65.6%
Progress: 7/11 features selected.

Feature set [8, 4, 11, 1, 3, 2, 9] was best, accuracy is 65.9%
Using feature(s) [8, 4, 11, 1, 3, 2, 9, 5] accuracy is 65.8%
Using feature(s) [8, 4, 11, 1, 3, 2, 9, 6] accuracy is 66.3%
Using feature(s) [8, 4, 11, 1, 3, 2, 9, 7] accuracy is 66.2%
Using feature(s) [8, 4, 11, 1, 3, 2, 9, 10] accuracy is 66.2%
Progress: 8/11 features selected.

Feature set [8, 4, 11, 1, 3, 2, 9, 6] was best, accuracy is 66.3%
Using feature(s) [8, 4, 11, 1, 3, 2, 9, 6, 5] accuracy is 65.9%
Using feature(s) [8, 4, 11, 1, 3, 2, 9, 6, 7] accuracy is 66.4%
Using feature(s) [8, 4, 11, 1, 3, 2, 9, 6, 10] accuracy is 67.0%
Progress: 9/11 features selected.

Feature set [8, 4, 11, 1, 3, 2, 9, 6, 10] was best, accuracy is 67.0%
Using feature(s) [8, 4, 11, 1, 3, 2, 9, 6, 10, 5] accuracy is 67.4%
Using feature(s) [8, 4, 11, 1, 3, 2, 9, 6, 10, 7] accuracy is 66.7%
Progress: 10/11 features selected.

Feature set [8, 4, 11, 1, 3, 2, 9, 6, 10, 5] was best, accuracy is 67.4%
Using feature(s) [8, 4, 11, 1, 3, 2, 9, 6, 10, 5, 7] accuracy is 67.4%
Progress: 11/11 features selected.

The best feature subset is [8, 4, 11, 1, 3, 2, 9, 6, 10, 5], which has an accuracy of 67.4%
The best three-feature subset is [8, 4, 11], which has an accuracy of 63.1%

Elapsed time: 9.364 seconds
(base) prakashkolluru@Prakashs-MBP AI Final script 2 % python3 main.py
Welcome to Bertie Woosters Feature Selection Algorithm.
Please select one : 1 - Synthetic Dataset, 2 - Real-World Dataset
2
Please select one : 1 - Red wine dataset, 2 - White wine dataset
2
This dataset has 11 features (not including the class attribute), with 4898 instances.
Please select the search algorithm: 1 - Forward Selection, 2 - Backward Elimination, 3 - Optimized Forward Selection, 4 - Optimized Backward Elimination
4
Starting Optimized Backward Elimination...
Running nearest neighbor with all 11 features, using "leaving-one-out" evaluation, I get accuracy of 67.4%

Using feature(s) [2, 3, 4, 5, 6, 7, 8, 9, 10, 11] accuracy is 66.0%
Using feature(s) [1, 3, 4, 5, 6, 7, 8, 9, 10, 11] accuracy is 66.0%
Using feature(s) [1, 2, 4, 5, 6, 7, 8, 9, 10, 11] accuracy is 67.3%
Using feature(s) [1, 2, 3, 5, 6, 7, 8, 9, 10, 11] accuracy is 67.0%
Using feature(s) [1, 2, 3, 4, 6, 7, 8, 9, 10, 11] accuracy is 66.7%
Using feature(s) [1, 2, 3, 4, 5, 7, 8, 9, 10, 11] accuracy is 66.6%
Using feature(s) [1, 2, 3, 4, 5, 6, 8, 9, 10, 11] accuracy is 67.4%
Using feature(s) [1, 2, 3, 4, 5, 6, 7, 9, 10, 11] accuracy is 67.5%
Using feature(s) [1, 2, 3, 4, 5, 6, 7, 8, 10, 11] accuracy is 66.2%
Using feature(s) [1, 2, 3, 4, 5, 6, 7, 8, 9, 11] accuracy is 66.4%
Using feature(s) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] accuracy is 66.5%
Progress: feature size is : 10

Feature set [1, 2, 3, 4, 5, 6, 7, 9, 10, 11] was best, accuracy is 67.5%
Using feature(s) [2, 3, 4, 5, 6, 7, 9, 10, 11] accuracy is 66.2%
Using feature(s) [1, 3, 4, 5, 6, 7, 9, 10, 11] accuracy is 65.9%
Using feature(s) [1, 2, 4, 5, 6, 7, 9, 10, 11] accuracy is 67.0%
Using feature(s) [1, 2, 3, 5, 6, 7, 9, 10, 11] accuracy is 66.7%
Using feature(s) [1, 2, 3, 4, 6, 7, 9, 10, 11] accuracy is 66.9%
Using feature(s) [1, 2, 3, 4, 5, 7, 9, 10, 11] accuracy is 66.5%
Using feature(s) [1, 2, 3, 4, 5, 6, 9, 10, 11] accuracy is 67.2%
Using feature(s) [1, 2, 3, 4, 5, 6, 7, 10, 11] accuracy is 66.2%
Using feature(s) [1, 2, 3, 4, 5, 6, 7, 9, 11] accuracy is 66.4%
Using feature(s) [1, 2, 3, 4, 5, 6, 7, 9, 10] accuracy is 65.6%
Progress: feature size is : 9

Using feature(s) [2, 3, 4, 5, 6, 9, 10, 11] accuracy is 66.1%
Using feature(s) [1, 3, 4, 5, 6, 9, 10, 11] accuracy is 65.4%
Using feature(s) [1, 2, 4, 5, 6, 9, 10, 11] accuracy is 67.0%
Using feature(s) [1, 2, 3, 5, 6, 9, 10, 11] accuracy is 66.4%
Using feature(s) [1, 2, 3, 4, 6, 9, 10, 11] accuracy is 67.2%
Using feature(s) [1, 2, 3, 4, 5, 9, 10, 11] accuracy is 66.7%
Using feature(s) [1, 2, 3, 4, 5, 6, 10, 11] accuracy is 66.3%
Using feature(s) [1, 2, 3, 4, 5, 6, 9, 11] accuracy is 66.1%
Using feature(s) [1, 2, 3, 4, 5, 6, 9, 10] accuracy is 65.7%
Progress: feature size is : 8

Using feature(s) [2, 3, 4, 6, 9, 10, 11] accuracy is 65.7%
Using feature(s) [1, 3, 4, 6, 9, 10, 11] accuracy is 64.9%
Using feature(s) [1, 2, 4, 6, 9, 10, 11] accuracy is 66.6%
Using feature(s) [1, 2, 3, 6, 9, 10, 11] accuracy is 66.3%
Using feature(s) [1, 2, 3, 4, 9, 10, 11] accuracy is 66.2%
Using feature(s) [1, 2, 3, 4, 6, 10, 11] accuracy is 66.5%
Using feature(s) [1, 2, 3, 4, 6, 9, 11] accuracy is 66.4%
Using feature(s) [1, 2, 3, 4, 6, 9, 10] accuracy is 65.1%
Progress: feature size is : 7

Using feature(s) [2, 4, 6, 9, 10, 11] accuracy is 65.6%
Using feature(s) [1, 4, 6, 9, 10, 11] accuracy is 65.4%
Using feature(s) [1, 2, 6, 9, 10, 11] accuracy is 65.8%
Using feature(s) [1, 2, 4, 9, 10, 11] accuracy is 66.2%
Using feature(s) [1, 2, 4, 6, 10, 11] accuracy is 65.9%
Using feature(s) [1, 2, 4, 6, 9, 11] accuracy is 65.6%
Using feature(s) [1, 2, 4, 6, 9, 10] accuracy is 64.3%
Progress: feature size is : 6

Using feature(s) [2, 4, 9, 10, 11] accuracy is 65.4%
Using feature(s) [1, 4, 9, 10, 11] accuracy is 65.0%
Using feature(s) [1, 2, 9, 10, 11] accuracy is 65.2%
Using feature(s) [1, 2, 4, 10, 11] accuracy is 64.5%
Using feature(s) [1, 2, 4, 9, 11] accuracy is 65.1%
Using feature(s) [1, 2, 4, 9, 10] accuracy is 62.6%
Progress: feature size is : 5

Using feature(s) [4, 9, 10, 11] accuracy is 63.4%
Using feature(s) [2, 9, 10, 11] accuracy is 64.8%
Using feature(s) [2, 4, 10, 11] accuracy is 63.8%
Using feature(s) [2, 4, 9, 11] accuracy is 63.4%
Using feature(s) [2, 4, 9, 10] accuracy is 62.1%
Progress: feature size is : 4

Using feature(s) [9, 10, 11] accuracy is 62.2%
Using feature(s) [2, 10, 11] accuracy is 61.6%
Using feature(s) [2, 9, 11] accuracy is 62.0%
Using feature(s) [2, 9, 10] accuracy is 59.0%
Progress: feature size is : 3

Using feature(s) [10, 11] accuracy is 45.8%
Using feature(s) [9, 11] accuracy is 46.7%
Using feature(s) [9, 10] accuracy is 42.5%
Progress: feature size is : 2

Using feature(s) [11] accuracy is 33.0%
Using feature(s) [9] accuracy is 24.9%
Progress: feature size is : 1

The best feature subset is [1, 2, 3, 4, 5, 6, 7, 9, 10, 11], which has an accuracy of 67.5%

Elapsed time: 13.129 seconds
